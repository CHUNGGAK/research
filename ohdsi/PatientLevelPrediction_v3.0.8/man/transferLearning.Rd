% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/DeepNN.R
\name{transferLearning}
\alias{transferLearning}
\title{[Under development] Transfer learning}
\usage{
transferLearning(plpResult, plpData, population, fixLayers = T,
  addLayers = c(100, 10), layerDropout = c(T, T),
  layerActivation = c("relu", "softmax"), batchSize = 10000, epochs = 20)
}
\arguments{
\item{plpResult}{The plp result when training a kersa deep learning model on big data}

\item{plpData}{The new data to fine tune the model on}

\item{population}{The population for the new data}

\item{fixLayers}{boolean vector for each layer in plpResult$model specificying whether to fix it e.g. c(T,T,F) means to fix layers 1 and 2 but not fox layer 3}

\item{addLayers}{vector specifying nodes in each layer to add e.g. c(100,10) will add another layer with 100 nodels and then a final layer with 10}

\item{layerDropout}{Add dropout to each new layer (binary vector length of addLayers)}

\item{layerActivation}{Activation function for each new layer (string vector length of addLayers)}

\item{batchSize}{Size of each batch for updating layers}

\item{epochs}{Number of epoches to run}
}
\description{
[Under development] Transfer learning
}
\examples{
\dontrun{
modelSet <- setDeepNN()
plpResult <- runPlp(plpData, population, modelSettings = modelSet, ...)

transferLearning(...)
}
}
